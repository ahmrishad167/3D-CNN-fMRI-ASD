{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3d_cnn1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmrishad167/3D-CNN-fMRI-ASD/blob/master/3d_cnn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PwYJXsC20kij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6d9e319b-8414-4761-c024-41f5da23cb2b"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
        "from keras.layers import Dropout, Input, BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adadelta\n",
        "import plotly.graph_objs as go\n",
        "from matplotlib.pyplot import cm\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import keras\n",
        "import h5py\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ePxEsbBs0qTg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with h5py.File('full_dataset_vectors.h5', 'r') as dataset:\n",
        "    x_train = dataset[\"X_train\"][:]\n",
        "    x_test = dataset[\"X_test\"][:]\n",
        "    y_train = dataset[\"y_train\"][:]\n",
        "    y_test = dataset[\"y_test\"][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0DJoIKTu0zUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "7ea91801-d667-4937-ef18-dbae7bea03af"
      },
      "cell_type": "code",
      "source": [
        "print (\"x_train shape: \", x_train.shape)\n",
        "print (\"y_train shape: \", y_train.shape)\n",
        "\n",
        "print (\"x_test shape:  \", x_test.shape)\n",
        "print (\"y_test shape:  \", y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (10000, 4096)\n",
            "y_train shape:  (10000,)\n",
            "x_test shape:   (2000, 4096)\n",
            "y_test shape:   (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lAMlZHQj03fV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Introduce the channel dimention in the input dataset \n",
        "xtrain = np.ndarray((x_train.shape[0], 4096, 3))\n",
        "xtest = np.ndarray((x_test.shape[0], 4096, 3))\n",
        "\n",
        "## iterate in train and test, add the rgb dimention \n",
        "def add_rgb_dimention(array):\n",
        "    scaler_map = cm.ScalarMappable(cmap=\"Oranges\")\n",
        "    array = scaler_map.to_rgba(array)[:, : -1]\n",
        "    return array\n",
        "for i in range(x_train.shape[0]):\n",
        "    xtrain[i] = add_rgb_dimention(x_train[i])\n",
        "for i in range(x_test.shape[0]):\n",
        "    xtest[i] = add_rgb_dimention(x_test[i])\n",
        "\n",
        "## convert to 1 + 4D space (1st argument represents number of rows in the dataset)\n",
        "xtrain = xtrain.reshape(x_train.shape[0], 16, 16, 16, 3)\n",
        "xtest = xtest.reshape(x_test.shape[0], 16, 16, 16, 3)\n",
        "\n",
        "## convert target variable into one-hot\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iuuVk1691ZO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f30a02f5-e87c-4b9b-a456-bb13227270bb"
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "8_jD6ztZ1d9X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## input layer\n",
        "input_layer = Input((16, 16, 16, 3))\n",
        "\n",
        "## convolutional layers\n",
        "conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu')(input_layer)\n",
        "conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu')(conv_layer1)\n",
        "\n",
        "## add max pooling to obtain the most imformatic features\n",
        "pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
        "\n",
        "conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
        "conv_layer4 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
        "conv_layer5 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(conv_layer4)\n",
        "pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer5)\n",
        "\n",
        "## perform batch normalization on the convolution outputs before feeding it to MLP architecture\n",
        "pooling_layer2 = BatchNormalization()(pooling_layer2)\n",
        "flatten_layer = Flatten()(pooling_layer2)\n",
        "\n",
        "## create an MLP architecture with dense layers : 4096 -> 512 -> 10\n",
        "## add dropouts to avoid overfitting / perform regularization\n",
        "dense_layer1 = Dense(units=2048, activation='relu')(flatten_layer)\n",
        "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
        "dense_layer2 = Dense(units=512, activation='relu')(dense_layer1)\n",
        "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
        "output_layer = Dense(units=10, activation='softmax')(dense_layer2)\n",
        "\n",
        "## define the model with input layer and output layer\n",
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bf6lKosy13Fi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "b1aea2ef-1de8-4bf8-8192-1b8402a716b4"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=categorical_crossentropy, optimizer=Adadelta(lr=0.1), metrics=['acc'])\n",
        "model.fit(x=xtrain, y=y_train, batch_size=128, epochs=5, validation_split=0.2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/5\n",
            "8000/8000 [==============================] - 99s 12ms/step - loss: 2.1721 - acc: 0.2339 - val_loss: 1.8372 - val_acc: 0.3505\n",
            "Epoch 2/5\n",
            "8000/8000 [==============================] - 98s 12ms/step - loss: 1.6744 - acc: 0.4315 - val_loss: 1.6658 - val_acc: 0.4455\n",
            "Epoch 3/5\n",
            "8000/8000 [==============================] - 98s 12ms/step - loss: 1.3714 - acc: 0.5260 - val_loss: 1.3381 - val_acc: 0.5400\n",
            "Epoch 4/5\n",
            "8000/8000 [==============================] - 98s 12ms/step - loss: 1.2106 - acc: 0.5805 - val_loss: 1.2991 - val_acc: 0.5455\n",
            "Epoch 5/5\n",
            "8000/8000 [==============================] - 98s 12ms/step - loss: 1.1235 - acc: 0.6060 - val_loss: 1.9449 - val_acc: 0.4285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26662bf7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "oRWqEE2w19KZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "e442c863-676a-4baf-b6b9-7a8503df558a"
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(xtest)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "pred"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-55416da3a338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected sequential_2_input to have 2 dimensions, but got array with shape (2000, 16, 16, 16, 3)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Ow2MsSC16b98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}